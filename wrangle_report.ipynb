{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a775928",
   "metadata": {},
   "source": [
    "## Wrangle Report\n",
    "\n",
    "This document briefly describes the wrangling efforts for the WeRateDogs Twitter dataset in the wrangle_act.ipynb notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd2d0d9",
   "metadata": {},
   "source": [
    "### About the Dataset(s)\n",
    "\n",
    "> The dataset I'll be wrangling is the tweet archive of Twitter user @dog_rates\n",
    "(https://twitter.com/dog_rates), also known as WeRateDogs. This archive/dataset consists of 2356 basic\n",
    "tweet data from November, 2015 to August, 2017. WeRateDogs is a Twitter account that rates people's\n",
    "dogs with a humorous comment about the dog.\n",
    "Based on the images in the above dataset (i.e. WeRateDogs Twitter archive), another dataset is\n",
    "created which consists of image predictions (the top three only) alongside each tweet ID, image URL,\n",
    "and the image number that corresponded to the most confident prediction (numbered 1 to 4 since\n",
    "tweets can have up to four images). Though no wrangling will be done directly on this image predictions\n",
    "dataset, it will definitely provide some additional data for our main tweet archive dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99947d8b",
   "metadata": {},
   "source": [
    "## Gathering Data\n",
    "\n",
    "The dataset was gather through the following methods:\n",
    "\n",
    "- File on hand - twitter_archive_enhanced.csv\n",
    "- File hosted on Udacity's servers - image_predictions.tsv\n",
    "- Query of Twitter API - tweet_json.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3316e9ae",
   "metadata": {},
   "source": [
    "- ***File on hand - twitter_archive_enhanced.csv***\n",
    "\n",
    "Using the link provided by Udacity, I downloaded the WeRateDogs Twitter archive manually as\n",
    "twitter_archive_enhanced.csv\n",
    "(https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958_twitter-archiveenhanced/twitter-archive-enhanced.csv) file and imported this file into a dataframe (df).\n",
    "\n",
    "\n",
    "- ***Gather tweet image predictions***\n",
    "\n",
    "I downloaded the tweet image predictions file hosted on Udacity's servers programmatically using\n",
    "Python's Requests library and saved it locally to image_predictions.tsv file. Then, I imported this file\n",
    "into a Python Pandas dataframe (df_image).\n",
    "\n",
    "\n",
    "- ***Query of Twitter API - tweet_json.txt***\n",
    "\n",
    "I couldn't get entrance into the twitter API so I downloaded a provided data from udacity server using python request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c92671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b1b66f2",
   "metadata": {},
   "source": [
    "## Assessing Data\n",
    "\n",
    "First of all, I was able to identify 2 quality issues just by going through the Key Points in the Project\n",
    "Motivation page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c028b27",
   "metadata": {},
   "source": [
    "- ***Visual Assessment***\n",
    "\n",
    "> I opened the twitter_archive_enhanced.csv and image_predictions.tsv using pandas and scrolled\n",
    "through them, looking for quality and tidiness issues. I was able to observe this \n",
    "\n",
    "### Quality\n",
    "\n",
    "- the columns in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id\tretweeted_status_user_id\tretweeted_status_timestamp are mostly null values in `twitter achive` table\n",
    "- Remove columns having retweet_id as we need only only original rating not retweets in `twitter achive` table\n",
    "- inconsitency in the tweet_id column name in the the three tavles\n",
    "- Some of the prediction are not dogs in the `image prediction` table\n",
    "\n",
    "### Tidyness\n",
    "\n",
    "- The doggo, pupper, poppo, and floofer columns should form a single colums called dog stage in `twitter achive` table\n",
    "- The name and dog stage can be extracted from the text column in `twitter achive` table\n",
    "- tweet_ID should be adjusted to tweet_id to conform with the two tables in the `additional file` table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4520602",
   "metadata": {},
   "source": [
    "- ***Programmatic Assessment***\n",
    "\n",
    "I then used pandas and a few of the methods to\n",
    "- .head()\n",
    "- .describe()\n",
    "- .info()\n",
    "- .duplicated()\n",
    "- .value_counts() .query()\n",
    "- .sum()\n",
    "\n",
    "### Quality\n",
    "\n",
    "##### twitter achive table\n",
    "\n",
    "- tweet_id should be in string\n",
    "- the columns retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp are all null values without duplicates, remove columns having retweet_id as we need only only original rating not retweets\n",
    "- data issue rating denominator having 00 change to 0\n",
    "- rating_denominator should be in int format as it is a rating number rather than strings\n",
    "- rating_numerator should be in int format as it is a rating number rather than strings\n",
    "- unneccesery html tags in the source column\n",
    "- rating_numerator column has values less than 10 as well as some very large numbers\n",
    "- rating_denominator column has values other than 10\n",
    "- remove index 8 row as it has so many missing values\n",
    "- Remove rows of tweets who tweet beyond august 1st, 2017\n",
    "- remove the rows of tweet_ids that retweeted since retweets are essentially duplicates of the actual tweets and so they may skew the result of your analysis \n",
    "- observed error values in the rating column\n",
    "\n",
    "#### Tidyness\n",
    "\n",
    "##### twitter achive table\n",
    "- The doggo, pupper, poppo, and floofer columns should form a single colums called dog stage\n",
    "- The name and dog stage can be extracted from the text column\n",
    "- convert timestamp to datetime column\n",
    "- Remove tweets beyond august 1st, 2017 in order to be able to merge successful with image_id as there are no augorithm result for date beyond august 1st, 2017. \n",
    "\n",
    "##### images\n",
    "\n",
    "\n",
    "##### twtcount\n",
    "- tweet_ID should be renamed to tweet_id to conform with the two tables\n",
    "- twtcount and df should be joined together and then joined with image data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ffd1c4",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "\n",
    "As all the quality and tidiness issues were related to `df_tweet_clean table`, I created a copy of only this table\n",
    "and named it archive_clean. For each quality/tidiness issue, I performed the programmatic data\n",
    "cleaning process in 3 stages - Define, Code & Test. During the cleaning process, I converted the\n",
    "datatypes of source and newly created stage columns of archive_clean to category datatype."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5c155e",
   "metadata": {},
   "source": [
    "## Storing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cb03c1",
   "metadata": {},
   "source": [
    "After the completion of the cleaning process, I stored the `df_tweet_clean table`  in\n",
    "twitter_archive_master.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb17fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
